{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773ef4c7",
   "metadata": {},
   "source": [
    "#Assignment 1 : Introduction to Deep learning by Ninad Sharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f384e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c7ccad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4676d6d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.add(1, 2))\n",
    "print(tf.math.add([1, 2], [3, 4]))\n",
    "print(tf.math.square(5))\n",
    "print(tf.math.reduce_sum([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1f65ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow operations convert numpy arrays to Tensors automatically\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
      "And NumPy operations convert Tensors to NumPy arrays automatically\n",
      "[[43. 43. 43.]\n",
      " [43. 43. 43.]\n",
      " [43. 43. 43.]]\n",
      "The .numpy() method explicitly converts a Tensor to a numpy array\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
    "tensor = tf.math.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "print(\"And NumPy operations convert Tensors to NumPy arrays automatically\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "652523d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a GPU available: \n",
      "[]\n",
      "Is the Tensor on GPU #0:  \n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform([3, 3])\n",
    "\n",
    "print(\"Is there a GPU available: \"),\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "print(\"Is the Tensor on GPU #0:  \"),\n",
    "print(x.device.endswith('GPU:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55e0d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Create a CSV file\n",
    "import tempfile\n",
    "_, filename = tempfile.mkstemp()\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "  f.write(\"\"\"Line 1\n",
    "Line 2\n",
    "Line 3\n",
    "  \"\"\")\n",
    "\n",
    "ds_file = tf.data.TextLineDataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc4386a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.string, name=None)>\n"
     ]
    }
   ],
   "source": [
    "print(ds_file.batch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c5018b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tensors = ds_tensors.map(tf.math.square).shuffle(2).batch(2)\n",
    "\n",
    "ds_file = ds_file.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d1e7cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements of ds_tensors:\n",
      "tf.Tensor([4 1], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 9 16], shape=(2,), dtype=int32)\n",
      "tf.Tensor([25 36], shape=(2,), dtype=int32)\n",
      "\n",
      "Elements in ds_file:\n",
      "tf.Tensor([b'Line 1' b'Line 2'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'Line 3' b'  '], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print('Elements of ds_tensors:')\n",
    "for x in ds_tensors:\n",
    "  print(x)\n",
    "\n",
    "print('\\nElements in ds_file:')\n",
    "for x in ds_file:\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb5ffce",
   "metadata": {},
   "source": [
    "MNIST Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb694af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import MNISTDataset\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee2ce6",
   "metadata": {},
   "source": [
    "#Issue with downloading dataset in mac : https://github.com/tensorflow/tensorflow/issues/33285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fee52cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.packages.urllib3.disable_warnings()\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "    pass\n",
    "else:\n",
    "    # Handle target environment that doesn't support HTTPS verification\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1839d4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db407d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x178dedb80>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[1], cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "284e6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MNISTDataset(train_images.reshape([-1, 784]), train_labels, \n",
    "                    test_images.reshape([-1, 784]), test_labels,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15815b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf5afe",
   "metadata": {},
   "source": [
    "#Single Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33981353",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "W = tf.Variable(np.zeros([784, 10]).astype(np.float32))\n",
    "b = tf.Variable(np.zeros(10, dtype=np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c41949ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3025853633880615 Accuracy: 0.0859375\n",
      "Loss: 0.6072514057159424 Accuracy: 0.828125\n",
      "Loss: 0.5264893770217896 Accuracy: 0.84375\n",
      "Loss: 0.5064999461174011 Accuracy: 0.84375\n",
      "Loss: 0.357225239276886 Accuracy: 0.9140625\n",
      "Starting new epoch...\n",
      "Loss: 0.48206374049186707 Accuracy: 0.8671875\n",
      "Loss: 0.42618468403816223 Accuracy: 0.8984375\n",
      "Loss: 0.39228808879852295 Accuracy: 0.90625\n",
      "Loss: 0.39353424310684204 Accuracy: 0.859375\n",
      "Loss: 0.37708163261413574 Accuracy: 0.90625\n",
      "Starting new epoch...\n"
     ]
    }
   ],
   "source": [
    "for step in range(train_steps):\n",
    "    img_batch, lbl_batch = data.next_batch()\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = tf.matmul(img_batch, W) + b\n",
    "        xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=lbl_batch))\n",
    "        \n",
    "    grads = tape.gradient(xent, [W, b])\n",
    "    W.assign_sub(learning_rate * grads[0])\n",
    "    b.assign_sub(learning_rate * grads[1])\n",
    "    \n",
    "    if not step % 100:\n",
    "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch),\n",
    "                             tf.float32))\n",
    "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1be445ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.9099, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_preds = tf.argmax(tf.matmul(data.test_data, W) + b, axis=1,\n",
    "                       output_type=tf.int32)\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, data.test_labels),\n",
    "                             tf.float32))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae5435",
   "metadata": {},
   "source": [
    "#Trying bias and weight with random number rather than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dbe6a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "W = tf.Variable(initial_value=np.random.rand(784, 10), dtype= tf.float32)\n",
    "b = tf.Variable(initial_value=np.random.rand(1, 10), dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "448b304f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88476865 0.89018703 0.22405178 0.02726407 0.7963819  0.34076886\n",
      " 0.914778   0.45738455 0.99280806 0.28405051]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.rand(784, 10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3fd37698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.9276106357574463 Accuracy: 0.0625\n",
      "Loss: 0.7936725616455078 Accuracy: 0.7578125\n",
      "Loss: 0.5452924966812134 Accuracy: 0.8359375\n",
      "Starting new epoch...\n",
      "Loss: 0.6472554206848145 Accuracy: 0.796875\n",
      "Loss: 0.49338507652282715 Accuracy: 0.875\n",
      "Loss: 0.4988260269165039 Accuracy: 0.828125\n",
      "Loss: 0.42869287729263306 Accuracy: 0.8984375\n",
      "Starting new epoch...\n",
      "Loss: 0.31067389249801636 Accuracy: 0.90625\n",
      "Loss: 0.4640328288078308 Accuracy: 0.859375\n",
      "Loss: 0.36461883783340454 Accuracy: 0.8984375\n"
     ]
    }
   ],
   "source": [
    "for step in range(train_steps):\n",
    "    img_batch, lbl_batch = data.next_batch()\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = tf.matmul(img_batch, W) + b\n",
    "        xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=lbl_batch))\n",
    "        \n",
    "    grads = tape.gradient(xent, [W, b])\n",
    "    W.assign_sub(learning_rate * grads[0])\n",
    "    b.assign_sub(learning_rate * grads[1])\n",
    "    \n",
    "    if not step % 100:\n",
    "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch),\n",
    "                             tf.float32))\n",
    "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2026cd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.8881, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_preds = tf.argmax(tf.matmul(data.test_data, W) + b, axis=1,\n",
    "                       output_type=tf.int32)\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, data.test_labels),\n",
    "                             tf.float32))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8e133b",
   "metadata": {},
   "source": [
    "#Not much diff in case of single layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150dcfaf",
   "metadata": {},
   "source": [
    "#Multi layer Neural network - (3 hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "350d4618",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the number of hidden units for each layer\n",
    "hidden_units = [256, 128, 64]\n",
    "\n",
    "#Training step same as single layer\n",
    "train_steps = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "W_input = tf.Variable(np.zeros([784, hidden_units[0]]).astype(np.float32))\n",
    "b_input = tf.Variable(np.zeros(hidden_units[0], dtype=np.float32))\n",
    "\n",
    "# Weight and bias variables for the first hidden layer\n",
    "W_hidden1 = tf.Variable(np.zeros([hidden_units[0], hidden_units[1]]).astype(np.float32))\n",
    "b_hidden1 = tf.Variable(np.zeros(hidden_units[1], dtype=np.float32))\n",
    "\n",
    "# Weight and bias variables for the second hidden layer\n",
    "W_hidden2 = tf.Variable(np.zeros([hidden_units[1], hidden_units[2]]).astype(np.float32))\n",
    "b_hidden2 = tf.Variable(np.zeros(hidden_units[2], dtype=np.float32))\n",
    "\n",
    "# Weight and bias variables for the output layer\n",
    "W_output = tf.Variable(np.zeros([hidden_units[2], 10]).astype(np.float32))\n",
    "b_output = tf.Variable(np.zeros(10, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08488d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3080732822418213 Accuracy: 0.09375\n",
      "Loss: 2.2988409996032715 Accuracy: 0.1171875\n",
      "Loss: 2.302356004714966 Accuracy: 0.140625\n",
      "Loss: 2.3069143295288086 Accuracy: 0.0859375\n",
      "Starting new epoch...\n",
      "Loss: 2.2904953956604004 Accuracy: 0.1640625\n",
      "Loss: 2.293233871459961 Accuracy: 0.1875\n",
      "Loss: 2.304719924926758 Accuracy: 0.1015625\n",
      "Loss: 2.2928009033203125 Accuracy: 0.1796875\n",
      "Loss: 2.299724817276001 Accuracy: 0.1171875\n",
      "Starting new epoch...\n",
      "Loss: 2.303908586502075 Accuracy: 0.1171875\n"
     ]
    }
   ],
   "source": [
    "for step in range(train_steps):\n",
    "    img_batch, lbl_batch = data.next_batch()\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass\n",
    "        hidden1 = tf.nn.relu(tf.matmul(img_batch, W_input) + b_input)\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, W_hidden1) + b_hidden1)\n",
    "        hidden3 = tf.nn.relu(tf.matmul(hidden2, W_hidden2) + b_hidden2)\n",
    "        logits = tf.matmul(hidden3, W_output) + b_output\n",
    "\n",
    "        xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=lbl_batch))\n",
    "\n",
    "    grads = tape.gradient(xent, [W_input, b_input, W_hidden1, b_hidden1, W_hidden2, b_hidden2, W_output, b_output])\n",
    "    W_input.assign_sub(learning_rate * grads[0])\n",
    "    b_input.assign_sub(learning_rate * grads[1])\n",
    "    W_hidden1.assign_sub(learning_rate * grads[2])\n",
    "    b_hidden1.assign_sub(learning_rate * grads[3])\n",
    "    W_hidden2.assign_sub(learning_rate * grads[4])\n",
    "    b_hidden2.assign_sub(learning_rate * grads[5])\n",
    "    W_output.assign_sub(learning_rate * grads[6])\n",
    "    b_output.assign_sub(learning_rate * grads[7])\n",
    "\n",
    "    if not step % 100:\n",
    "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch), tf.float32))\n",
    "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
    "\n",
    "# test_preds = tf.argmax(tf.matmul(data.test_data, W_output) + b_output, axis=1, output_type=tf.int32)\n",
    "# acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, data.test_labels), tf.float32))\n",
    "# print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48e47f",
   "metadata": {},
   "source": [
    "#Low accuracy if we take weights and bias as zeroes - issues of Symmetry,Vanishing Gradients:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0626995b",
   "metadata": {},
   "source": [
    "#Trying with random weights and bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8959d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize weights with random values in the range [-0.1, 0.1]\n",
    "def initialize_weights(shape):\n",
    "    return tf.Variable(np.random.uniform(low=-0.1, high=0.1, size=shape).astype(np.float32))\n",
    "\n",
    "# Function to initialize biases with random values in the range [-0.1, 0.1]\n",
    "def initialize_biases(shape):\n",
    "    return tf.Variable(np.random.uniform(low=-0.1, high=0.1, size=shape).astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd350164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3284106254577637 Accuracy: 0.0546875\n",
      "Loss: 0.4395413398742676 Accuracy: 0.859375\n",
      "Loss: 0.3180759847164154 Accuracy: 0.875\n",
      "Starting new epoch...\n",
      "Loss: 0.3246888816356659 Accuracy: 0.90625\n",
      "Loss: 0.25551339983940125 Accuracy: 0.9296875\n",
      "Loss: 0.18595102429389954 Accuracy: 0.9453125\n",
      "Loss: 0.14288140833377838 Accuracy: 0.953125\n",
      "Starting new epoch...\n",
      "Loss: 0.1964898705482483 Accuracy: 0.953125\n",
      "Loss: 0.17829769849777222 Accuracy: 0.953125\n",
      "Loss: 0.11838220804929733 Accuracy: 0.9765625\n",
      "tf.Tensor(0.1166, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "hidden_units = [256, 128, 784]\n",
    "# Initialize weights and biases\n",
    "W_input = initialize_weights([784, hidden_units[0]])\n",
    "b_input = initialize_biases([hidden_units[0]])\n",
    "W_hidden1 = initialize_weights([hidden_units[0], hidden_units[1]])\n",
    "b_hidden1 = initialize_biases([hidden_units[1]])\n",
    "W_hidden2 = initialize_weights([hidden_units[1], hidden_units[2]])\n",
    "b_hidden2 = initialize_biases([hidden_units[2]])\n",
    "W_output = initialize_weights([hidden_units[2], 10])\n",
    "b_output = initialize_biases([10])\n",
    "\n",
    "for step in range(train_steps):\n",
    "    img_batch, lbl_batch = data.next_batch()\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass\n",
    "        hidden1 = tf.nn.relu(tf.matmul(img_batch, W_input) + b_input)\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, W_hidden1) + b_hidden1)\n",
    "        hidden3 = tf.nn.relu(tf.matmul(hidden2, W_hidden2) + b_hidden2)\n",
    "        logits = tf.matmul(hidden3, W_output) + b_output\n",
    "\n",
    "        xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=lbl_batch))\n",
    "\n",
    "    grads = tape.gradient(xent, [W_input, b_input, W_hidden1, b_hidden1, W_hidden2, b_hidden2, W_output, b_output])\n",
    "    \n",
    "    # Update weights and biases\n",
    "    W_input.assign_sub(learning_rate * grads[0])\n",
    "    b_input.assign_sub(learning_rate * grads[1])\n",
    "    W_hidden1.assign_sub(learning_rate * grads[2])\n",
    "    b_hidden1.assign_sub(learning_rate * grads[3])\n",
    "    W_hidden2.assign_sub(learning_rate * grads[4])\n",
    "    b_hidden2.assign_sub(learning_rate * grads[5])\n",
    "    W_output.assign_sub(learning_rate * grads[6])\n",
    "    b_output.assign_sub(learning_rate * grads[7])\n",
    "\n",
    "    if not step % 100:\n",
    "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch), tf.float32))\n",
    "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
    "test_preds = tf.argmax(tf.matmul(data.test_data, W_output) + b_output, axis=1, output_type=tf.int32)\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, data.test_labels), tf.float32))\n",
    "print(acc)\n",
    "#print(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4d2512",
   "metadata": {},
   "source": [
    "#This shows that initializing weights with 0 does not work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
